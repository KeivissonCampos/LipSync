<!DOCTYPE html>
<html lang="pt-BR">

<head>
    <meta charset="UTF-8">
    <title>Azure TTS com Lipsync</title>
    <script src="https://aka.ms/csspeech/jsbrowserpackageraw"></script>
    <style>
        #mouth {
            width: 200px;
            height: 200px;
            border: 1px solid #ccc;
        }
    </style>
    <script src="config.js"></script>
</head>

<body>
    <h2>Azure TTS + Lipsync V4.0</h2>
    <input type="text" id="text" placeholder="Digite o texto" size="50">
    <button onclick="speak()">Falar</button>
    <br><br>
    <img id="mouth" src="./img/viseme_0.png" alt="boca">
    
    <script>
        const subscriptionKey = azureConfig.subscriptionKey;
        const serviceRegion = azureConfig.serviceRegion;

        let visemes = [];
        let currentIndex = 0;
        let audioStartTime = 0;

        async function speak() {
            const text = document.getElementById("text").value;
            if (!text) return;

            visemes = [];
            currentIndex = 0;

            const speechConfig = SpeechSDK.SpeechConfig.fromSubscription(subscriptionKey, serviceRegion);
            speechConfig.speechSynthesisVoiceName = "pt-BR-AntonioNeural";
            speechConfig.setProperty(SpeechSDK.PropertyId.SpeechServiceResponse_RequestViseme, "true");

            const player = new SpeechSDK.SpeakerAudioDestination();
            const audioConfig = SpeechSDK.AudioConfig.fromSpeakerOutput(player);
            const synthesizer = new SpeechSDK.SpeechSynthesizer(speechConfig, audioConfig);

            synthesizer.visemeReceived = (s, e) => {
                const offset = e.audioOffset / 10000000.0;
                visemes.push({ viseme: e.visemeId, time: offset });
            };

            player.onAudioStart = () => {
                setTimeout(() => {
                    audioStartTime = performance.now() / 1000;
                    startAnimation();
                }, 100); // atraso leve para garantir sincronia
            };

            synthesizer.speakTextAsync(
                text,
                result => {
                    if (result.reason !== SpeechSDK.ResultReason.SynthesizingAudioCompleted) {
                        console.error("Erro na sÃ­ntese:", result.errorDetails);
                    }
                    synthesizer.close();
                },
                err => {
                    console.error("Erro:", err);
                    synthesizer.close();
                }
            );
        }

        function startAnimation() {
            const mouth = document.getElementById("mouth");

            function update() {
                if (currentIndex >= visemes.length) return;

                const now = performance.now() / 1000;
                const elapsed = now - audioStartTime;

                const next = visemes[currentIndex];
                if (elapsed >= next.time) {
                    mouth.src = `./img/viseme_${next.viseme}.png`;
                    currentIndex++;
                }

                requestAnimationFrame(update);
            }

            requestAnimationFrame(update);
        }
    </script>
</body>

</html>
